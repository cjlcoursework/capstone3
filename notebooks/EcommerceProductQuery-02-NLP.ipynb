{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<br/>\n",
    "\n",
    "# <font color=teal>Ecommerce Shopping Project</font>\n",
    "\n",
    "This project is based on the Amazon KDD Cup 2023 challenge to classify customer shopping queries as related or not related to product descriptions\n",
    "\n",
    "find the challenge [Here](https://www.aicrowd.com/challenges/amazon-kdd-cup-23-multilingual-recommendation-challenge)\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<br/>\n",
    "\n",
    "## <font color=orange>Step 2 - Tokenize product and query text</font>\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "### <font color=orange>Goal</font>\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "- Tokenize the prpepared data\n",
    "\n",
    "- Save as a hugging face dataset\n",
    "\n",
    "<br/>\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "### <font color=orange>Input</font>\n",
    "<font color=purple>Local clean data </font>\n",
    "\n",
    "<font color=purple>Spanish</font>\n",
    "\n",
    "- `es_prod_query_0.parquet`\n",
    "- `es_prod_query_1.parquet`\n",
    "-`es_prod_query_2.parquet`\n",
    "- `es_prod_query_3.parquet`\n",
    "- `es_prod_query_4.parquet`\n",
    "\n",
    "<font color=purple>Japanese</font>\n",
    "\n",
    "- `jp_prod_query_0.parquet`\n",
    "- `jp_prod_query_1.parquet`\n",
    "- `jp_prod_query_2.parquet`\n",
    "- `jp_prod_query_3.parquet`\n",
    "- `jp_prod_query_4.parquet`\n",
    "- `jp_prod_query_5.parquet`\n",
    "\n",
    "<font color=purple>English</font>\n",
    "\n",
    "- `us_prod_query_0.parquet`\n",
    "- `us_prod_query_1.parquet`\n",
    "- `us_prod_query_2.parquet`\n",
    "- `us_prod_query_3.parquet`\n",
    "- `us_prod_query_4.parquet`\n",
    "- `us_prod_query_5.parquet`\n",
    "\n",
    "<font color=purple>Metadata</font>\n",
    " `metadata.json`\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "### <font color=orange>Approach</font>\n",
    "\n",
    "Read in the clean dataset we created earlier\n",
    " \n",
    "Tokenize the test columns using the pre-trained hugging-face ```sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2``` model \n",
    "\n",
    "We'll use this prepared data in subsequent steps to train the model and make predictions\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "<br/>\n",
    "\n",
    "### <font color=orange>Output</font>\n",
    "\n",
    "<font color=purple>Local tokenized data </font>\n",
    "\n",
    "Data nlp directory\n",
    "\n",
    "- <font color=purple>dataset_info.json</font>\n",
    "\n",
    "- <font color=purple>state.json</font>\n",
    "\n",
    "\n",
    "- <font color=purple>train</font>\n",
    "    \n",
    "    - `data-00000-of-000003.arrow`\n",
    "    - `data-00001-of-000003.arrow`\n",
    "    - `data-00002-of-000003.arrow`\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5aa44cadd583fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "\n",
    "#### <a id=\"top\"></a>\n",
    "\n",
    "<div style=\"background-color: teal; padding: 10px;\">\n",
    "    <h3 style=\"color: white;\">Table of contents</h3>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: rgba(60, 121, 245, 0.03); padding:30px; font-size:15px; font-family: consolas;\">\n",
    "<ul>\n",
    "    <li><a href=\"#0\" target=\"_self\" rel=\" noreferrer nofollow\">0. Imports and housekeeping</a></li>\n",
    "    <li><a href=\"#1\" target=\"_self\" rel=\" noreferrer nofollow\">1. AI Crowd Login</a></li>\n",
    "    <li><a href=\"#2\" target=\"_self\" rel=\" noreferrer nofollow\">2. Read untokenized data</a></li>\n",
    "    <li><a href=\"#2\" target=\"_self\" rel=\" noreferrer nofollow\">3. Add tokenized columns</a></li>\n",
    "    <li><a href=\"#2\" target=\"_self\" rel=\" noreferrer nofollow\">4. Save as a hugging face dataset</a></li>\n",
    "\n",
    "</ul>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f96c68d219178d0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"0\"></a>\n",
    "<div style=\"background-color: teal; padding: 10px;\">\n",
    "    <h3 style=\"color: white;\">Imports and housekeeping</h3>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c505fb9cd18133d"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../src')  # Add the 'src' directory to the Python path\n",
    "sys.path.append('../_secrets')  # Add the 'src' directory to the Python path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T01:04:42.359866Z",
     "start_time": "2023-10-08T01:04:42.322874Z"
    }
   },
   "id": "2fd122bbf03fe34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf### models\n",
    "import numpy as np### math computations\n",
    "import matplotlib.pyplot as plt### plotting bar chart\n",
    "import sklearn### machine learning library\n",
    "# import cv2## image processing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve### metrics\n",
    "import seaborn as sns### visualizations\n",
    "import datetime\n",
    "import pathlib\n",
    "import io\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import string\n",
    "import time\n",
    "from numpy import random\n",
    "# import gensim.downloader as api\n",
    "from PIL import Image\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Dense,Flatten,InputLayer,BatchNormalization,Dropout,Input,LayerNormalization\n",
    "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from google.colab import drive\n",
    "# from google.colab import files\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Local\n",
    "from _secrets.secret_vars import get_secret\n",
    "from src.config import get_directory, get_config\n",
    "import json\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6c8cfee93c09a978"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"1\"></a>\n",
    "<div style=\"background-color: teal; padding: 10px;\">\n",
    "    <h3 style=\"color: white;\">AI Crowd Login</h3>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26bd564843bbc9f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the AI crown key from 'secrets' source"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b9455105083274e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "api_key = get_secret('api_key')\n",
    "os.environ[\"AICROWD_API_KEY\"] = api_key"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-08T01:04:46.356018Z"
    }
   },
   "id": "8bf22c1debeee9a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Login"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81b89558cd894580"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! aicrowd login "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6aef0ec9859cb4ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"2\"></a>\n",
    "\n",
    "<div style=\"background-color: teal; padding: 10px;\">\n",
    "    <h3 style=\"color: white;\">Read untokenized data</h3>\n",
    "</div>\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77fe107da9eb1fdf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read our metadata file"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa7942e1584c6cf7"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "meta_file = os.path.join(get_directory('prep_data'), 'metadata.json')\n",
    "\n",
    "with open(meta_file, 'r') as fp:\n",
    "    meta = json.load(fp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T01:04:46.360606Z",
     "start_time": "2023-10-08T01:04:46.358714Z"
    }
   },
   "id": "4d0daf7b7043fb9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['/Users/christopherlomeli/Source/courses/datascience/Springboard/capstone/capstone3/data/prep/us/us_prod_query_0.parquet',\n '/Users/christopherlomeli/Source/courses/datascience/Springboard/capstone/capstone3/data/prep/us/us_prod_query_1.parquet',\n '/Users/christopherlomeli/Source/courses/datascience/Springboard/capstone/capstone3/data/prep/us/us_prod_query_2.parquet',\n '/Users/christopherlomeli/Source/courses/datascience/Springboard/capstone/capstone3/data/prep/us/us_prod_query_3.parquet',\n '/Users/christopherlomeli/Source/courses/datascience/Springboard/capstone/capstone3/data/prep/us/us_prod_query_4.parquet',\n '/Users/christopherlomeli/Source/courses/datascience/Springboard/capstone/capstone3/data/prep/us/us_prod_query_5.parquet',\n '/Users/christopherlomeli/Source/courses/datascience/Springboard/capstone/capstone3/data/prep/us/us_prod_query_6.parquet',\n '/Users/christopherlomeli/Source/courses/datascience/Springboard/capstone/capstone3/data/prep/us/us_prod_query_7.parquet',\n '/Users/christopherlomeli/Source/courses/datascience/Springboard/capstone/capstone3/data/prep/us/us_prod_query_8.parquet']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_files = meta['us']\n",
    "us_files"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T01:04:46.364665Z",
     "start_time": "2023-10-08T01:04:46.362255Z"
    }
   },
   "id": "8c2280858de38570"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "# Read all the Parquet files into a single DataFrame\n",
    "df = pd.concat([pd.read_parquet(file) for file in [us_files[0]]], ignore_index=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T01:04:46.436959Z",
     "start_time": "2023-10-08T01:04:46.365027Z"
    }
   },
   "id": "a2fd68007fc62d6e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "<div style=\"background-color: teal; padding: 10px;\">\n",
    "    <h3 style=\"color: white;\">Add tokenized columns</h3>\n",
    "</div>\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bf0d6fba53ba1dd"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "MAX_LENGTH=64\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T01:04:46.438972Z",
     "start_time": "2023-10-08T01:04:46.437481Z"
    }
   },
   "id": "a93f8e3a476b5008"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_id=get_config(\"model_id\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T01:04:46.882818Z",
     "start_time": "2023-10-08T01:04:46.440282Z"
    }
   },
   "id": "472a2dd295d35981"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize 'query' and 'product' columns using the BERT tokenizer\n",
    "tokenized_query = tokenizer(df['query'].tolist(), max_length=MAX_LENGTH, padding='max_length', truncation=True)\n",
    "tokenized_product = tokenizer(df['product'].tolist(), max_length=MAX_LENGTH, padding='max_length', truncation=True)\n",
    "\n",
    "# Add tokenized outputs to the DataFrame\n",
    "df['input_ids_query'] = tokenized_query['input_ids']\n",
    "df['token_type_ids_query'] = tokenized_query['token_type_ids']\n",
    "df['attention_mask_query'] = tokenized_query['attention_mask']\n",
    "\n",
    "df['input_ids_product'] = tokenized_product['input_ids']\n",
    "df['token_type_ids_product'] = tokenized_product['token_type_ids']\n",
    "df['attention_mask_product'] = tokenized_product['attention_mask']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T01:04:51.959744Z",
     "start_time": "2023-10-08T01:04:46.894090Z"
    }
   },
   "id": "49e043e5cdc35600"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"4\"></a>\n",
    "\n",
    "<div style=\"background-color: teal; padding: 10px;\">\n",
    "    <h3 style=\"color: white;\">Save as a hugging face dataset</h3>\n",
    "</div>\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77473c53f79b82d9"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': Dataset.from_pandas(df)\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T01:04:52.441850Z",
     "start_time": "2023-10-08T01:04:51.960498Z"
    }
   },
   "id": "77bc700e9d8e017b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "stage_dir = os.path.join(get_directory('data'), 'nlp' )\n",
    "if not os.path.exists(stage_dir):\n",
    "    os.makedirs(stage_dir)\n",
    "    \n",
    "nlp_data = os.path.join(stage_dir, 'us_tokenized')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T01:04:52.445235Z",
     "start_time": "2023-10-08T01:04:52.442104Z"
    }
   },
   "id": "6c8d306b18862058"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/53191 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36c81b32656740d18cf36951934490fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.6 ms, sys: 236 ms, total: 272 ms\n",
      "Wall time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "dataset_dict.save_to_disk(nlp_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T01:04:53.625302Z",
     "start_time": "2023-10-08T01:04:52.443638Z"
    }
   },
   "id": "8fea4b209674e7b3"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T01:04:53.627518Z",
     "start_time": "2023-10-08T01:04:53.626024Z"
    }
   },
   "id": "d748cb55cdf7bda"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
