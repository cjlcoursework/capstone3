{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<br/>\n",
    "\n",
    "# <font color=teal>Ecommerce Shopping Project</font>\n",
    "\n",
    "This project is based on the Amazon KDD Cup 2023 challenge to classify customer shopping queries as related or not related to product descriptions\n",
    "\n",
    "find the challenge [Here](https://www.aicrowd.com/challenges/amazon-kdd-cup-23-multilingual-recommendation-challenge)\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/>\n",
    "\n",
    "## <font color=orange>Step 4 - Test the model</font>\n",
    "\n",
    "<br/>\n",
    "\n",
    "Load the SBERT model\n",
    "\n",
    "Load the weights we got from training and saved in step 3\n",
    "\n",
    "Try to print the top 5 matches to a customer query\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "### <font color=orange>Goal</font>\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "Correctly pick the best matches to a customer query \n",
    "\n",
    "<br/>\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "### <font color=orange>Input</font>\n",
    "\n",
    "The trained weights from our model \n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "### <font color=orange>Approach</font>\n",
    "\n",
    "Load the weights we trained\n",
    "\n",
    "Tokenize the product titles \n",
    "\n",
    "When we get a query, score all product titles and sort them in order of relevance\n",
    "\n",
    "Return the top n products that match the customer's query\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "<br/>\n",
    "\n",
    "### <font color=orange>Output</font>\n",
    "\n",
    "The top n products for a customer's query\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "0gfd5CJZ_yDc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "\n",
    "#### <a id=\"top\"></a>\n",
    "\n",
    "<div style=\"background-color: teal; padding: 10px;\">\n",
    "    <h3 style=\"color: white;\">Table of contents</h3>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: rgba(60, 121, 245, 0.03); padding:30px; font-size:15px; font-family: consolas;\">\n",
    "<ul>\n",
    "    <li><a href=\"#0\" target=\"_self\" rel=\" noreferrer nofollow\">0. Imports and housekeeping</a></li>\n",
    "    <li><a href=\"#1\" target=\"_self\" rel=\" noreferrer nofollow\">1. AI Crowd Login</a></li>\n",
    "    <li><a href=\"#2\" target=\"_self\" rel=\" noreferrer nofollow\">2. Read untokenized data</a></li>\n",
    "    <li><a href=\"#2\" target=\"_self\" rel=\" noreferrer nofollow\">3. Add tokenized columns</a></li>\n",
    "    <li><a href=\"#2\" target=\"_self\" rel=\" noreferrer nofollow\">4. Save as a hugging face dataset</a></li>\n",
    "\n",
    "</ul>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "id": "-nN65mkR_yDe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "id": "BRmLGAHZ_yDe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"0\"></a>\n",
    "<div style=\"background-color: teal; padding: 10px;\">\n",
    "    <h3 style=\"color: white;\">Housekeeping</h3>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "id": "WYQvQoqx_yDf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Environment"
   ],
   "metadata": {
    "collapsed": false,
    "id": "NWnPemDN_yDf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "def install_if_not_installed(package_name):\n",
    "    try:\n",
    "        importlib.import_module(package_name)  # Try to import the package\n",
    "    except ImportError:\n",
    "        print(f\"\\n=========================\\ninstalling {package_name}\\n=========================\")\n",
    "        !pip install {package_name}  # If it's not installed, install it"
   ],
   "metadata": {
    "id": "X9emKTUM_yDf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696714043350,
     "user_tz": 420,
     "elapsed": 793,
     "user": {
      "displayName": "Chris Lomeli",
      "userId": "08772038892035982771"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-10-08T01:07:45.789546Z",
     "start_time": "2023-10-08T01:07:45.786529Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================\n",
      "installing aicrowd-cli\n",
      "=========================\n",
      "Requirement already satisfied: aicrowd-cli in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (0.1.15)\r\n",
      "Requirement already satisfied: click<8,>=7.1.2 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from aicrowd-cli) (7.1.2)\r\n",
      "Requirement already satisfied: GitPython==3.1.18 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from aicrowd-cli) (3.1.18)\r\n",
      "Requirement already satisfied: requests<3,>=2.25.1 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from aicrowd-cli) (2.31.0)\r\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.9.1 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from aicrowd-cli) (0.10.1)\r\n",
      "Requirement already satisfied: rich<11,>=10.0.0 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from aicrowd-cli) (10.16.2)\r\n",
      "Requirement already satisfied: toml<1,>=0.10.2 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from aicrowd-cli) (0.10.2)\r\n",
      "Requirement already satisfied: tqdm<5,>=4.56.0 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from aicrowd-cli) (4.65.0)\r\n",
      "Requirement already satisfied: pyzmq==22.1.0 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from aicrowd-cli) (22.1.0)\r\n",
      "Requirement already satisfied: python-slugify<6,>=5.0.0 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from aicrowd-cli) (5.0.2)\r\n",
      "Requirement already satisfied: semver<3,>=2.13.0 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from aicrowd-cli) (2.13.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from GitPython==3.1.18->aicrowd-cli) (4.0.10)\r\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from python-slugify<6,>=5.0.0->aicrowd-cli) (1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from requests<3,>=2.25.1->aicrowd-cli) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from requests<3,>=2.25.1->aicrowd-cli) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from requests<3,>=2.25.1->aicrowd-cli) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from requests<3,>=2.25.1->aicrowd-cli) (2023.5.7)\r\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in /Users/christopherlomeli/.local/lib/python3.9/site-packages (from rich<11,>=10.0.0->aicrowd-cli) (0.4.4)\r\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from rich<11,>=10.0.0->aicrowd-cli) (0.9.1)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from rich<11,>=10.0.0->aicrowd-cli) (2.15.1)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/christopherlomeli/anaconda3/envs/ml_play_kitchensink/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython==3.1.18->aicrowd-cli) (5.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "install_if_not_installed('transformers')\n",
    "install_if_not_installed('datasets')\n",
    "install_if_not_installed('aicrowd-cli')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQuZ3-G9_yDg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696714049892,
     "user_tz": 420,
     "elapsed": 5372,
     "user": {
      "displayName": "Chris Lomeli",
      "userId": "08772038892035982771"
     }
    },
    "outputId": "b858ef58-d764-4bef-c0be-5ff14ef59e3c",
    "ExecuteTime": {
     "end_time": "2023-10-08T01:07:48.092127Z",
     "start_time": "2023-10-08T01:07:45.790627Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false,
    "id": "UCaZgoY4_yDg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pathlib\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import csv\n",
    "import string\n",
    "import time\n",
    "from numpy import random\n",
    "# import gensim.downloader as api\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "\n",
    "from datasets import load_dataset, load_from_disk, DatasetDict\n",
    "from transformers import AutoTokenizer,create_optimizer,TFAutoModel\n",
    "\n",
    "# Local\n",
    "\n",
    "import json"
   ],
   "metadata": {
    "id": "Sk-41kD5_yDh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696714053587,
     "user_tz": 420,
     "elapsed": 3699,
     "user": {
      "displayName": "Chris Lomeli",
      "userId": "08772038892035982771"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-10-08T01:07:50.667250Z",
     "start_time": "2023-10-08T01:07:48.092955Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"0\"></a>\n",
    "<div style=\"background-color: teal; padding: 10px;\">\n",
    "    <h3 style=\"color: white;\">Colab Setup</h3>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "id": "PlCO30lM_yDh"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "mount Google Drive and import local packages"
   ],
   "metadata": {
    "collapsed": false,
    "id": "vlmHjCCQ_yDh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "# Check if running in Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    from google.colab import files\n",
    "\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    from drive.MyDrive.projects.capstone3.source.sentence_transformer import TransformerModel\n",
    "    from drive.MyDrive.projects.capstone3.source.config import get_config, get_directory\n",
    "    from drive.MyDrive.projects.capstone3.source.secrets import get_secret\n",
    "\n",
    "else:\n",
    "    sys.path.append('../src')  # Add the 'src' directory to the Python path\n",
    "    sys.path.append('../_secrets')  # Add the 'src' directory to the Python path\n",
    "\n",
    "    from src.sentence_transformer import TransformerModel\n",
    "    from src.config import get_directory, get_config, get_directory\n",
    "    from _secrets.secret_vars import get_secret\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrH1Lqsl_yDh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696714056078,
     "user_tz": 420,
     "elapsed": 2495,
     "user": {
      "displayName": "Chris Lomeli",
      "userId": "08772038892035982771"
     }
    },
    "outputId": "5fa29686-975e-48f4-b775-ab7a8123d4e4",
    "ExecuteTime": {
     "end_time": "2023-10-08T01:07:51.378787Z",
     "start_time": "2023-10-08T01:07:50.668866Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check GPU"
   ],
   "metadata": {
    "collapsed": false,
    "id": "BbPLs87D_yDh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "\n",
    "    gpu_info = !nvidia-smi\n",
    "    gpu_info = '\\n'.join(gpu_info)\n",
    "    if gpu_info.find('failed') >= 0:\n",
    "      print('Not connected to a GPU')\n",
    "    else:\n",
    "      print(gpu_info)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jGDICN_k_yDh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696714056079,
     "user_tz": 420,
     "elapsed": 18,
     "user": {
      "displayName": "Chris Lomeli",
      "userId": "08772038892035982771"
     }
    },
    "outputId": "4ece347e-6753-4e28-ed6f-1245c65aa437",
    "ExecuteTime": {
     "end_time": "2023-10-08T01:07:51.385963Z",
     "start_time": "2023-10-08T01:07:51.381215Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check Ram"
   ],
   "metadata": {
    "collapsed": false,
    "id": "gqbQdN70_yDi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Check free RAM\n",
    "if 'google.colab' in sys.modules:\n",
    "    !free -h"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QrYO-olA_yDi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696714056079,
     "user_tz": 420,
     "elapsed": 8,
     "user": {
      "displayName": "Chris Lomeli",
      "userId": "08772038892035982771"
     }
    },
    "outputId": "f6fa84e0-8a58-4a36-dd7c-19879ac15adc",
    "ExecuteTime": {
     "end_time": "2023-10-08T01:07:51.386149Z",
     "start_time": "2023-10-08T01:07:51.383438Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check GPU"
   ],
   "metadata": {
    "collapsed": false,
    "id": "4BFr0i1f_yDi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 18:07:51.386662: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2023-10-07 18:07:51.386689: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-10-07 18:07:51.386692: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-10-07 18:07:51.386877: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-07 18:07:51.386904: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BN8HQDb8_yDi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696714056561,
     "user_tz": 420,
     "elapsed": 15,
     "user": {
      "displayName": "Chris Lomeli",
      "userId": "08772038892035982771"
     }
    },
    "outputId": "8db0104c-bdbb-487c-c4e0-3500c9a3390a",
    "ExecuteTime": {
     "end_time": "2023-10-08T01:07:51.395079Z",
     "start_time": "2023-10-08T01:07:51.392230Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 17.2 gigabytes of available RAM\n",
      "\n",
      "!!!!!!!!!!!!  Not using a high-RAM runtime  !!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('!!!!!!!!!!!!  Not using a high-RAM runtime  !!!!!!!!!!!!!!!!!!')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhaVUL9G_yDi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696714056561,
     "user_tz": 420,
     "elapsed": 9,
     "user": {
      "displayName": "Chris Lomeli",
      "userId": "08772038892035982771"
     }
    },
    "outputId": "061a3021-bac3-4e3d-dd2e-8f8ecbc0df9d",
    "ExecuteTime": {
     "end_time": "2023-10-08T01:07:51.397121Z",
     "start_time": "2023-10-08T01:07:51.395544Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"0\"></a>\n",
    "<div style=\"background-color: teal; padding: 10px;\">\n",
    "    <h3 style=\"color: white;\">Ai Crowd Setup Setup</h3>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "id": "t874hLE0_yDi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1696714056562,
     "user": {
      "displayName": "Chris Lomeli",
      "userId": "08772038892035982771"
     },
     "user_tz": 420
    },
    "id": "fvDSmkoyKVTy",
    "ExecuteTime": {
     "end_time": "2023-10-08T01:07:51.404218Z",
     "start_time": "2023-10-08T01:07:51.397969Z"
    }
   },
   "outputs": [],
   "source": [
    "api_key = get_secret('api_key')\n",
    "os.environ[\"AICROWD_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2635,
     "status": "ok",
     "timestamp": 1696714059191,
     "user": {
      "displayName": "Chris Lomeli",
      "userId": "08772038892035982771"
     },
     "user_tz": 420
    },
    "id": "b3k1BWUqNkaW",
    "outputId": "06041c77-936a-44bd-dcf9-2db7f52e6562",
    "ExecuteTime": {
     "end_time": "2023-10-08T01:07:55.288796Z",
     "start_time": "2023-10-08T01:07:51.400324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mAPI Key valid\u001B[0m\r\n",
      "\u001B[33mGitlab oauth token invalid or absent.\r\n",
      "It is highly recommended to simply run `aicrowd login` without passing the API Key.\u001B[0m\r\n",
      "\u001B[32mSaved details successfully!\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "! aicrowd login"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"0\"></a>\n",
    "<div style=\"background-color: teal; padding: 10px;\">\n",
    "    <h3 style=\"color: white;\">Get the model from Hugging Face, and load our own weights</h3>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Z28nq-Zm_yDj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE=128\n",
    "LEARNING_RATE = .0001"
   ],
   "metadata": {
    "id": "9Ct4m-yx_yDj",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696714059191,
     "user_tz": 420,
     "elapsed": 3,
     "user": {
      "displayName": "Chris Lomeli",
      "userId": "08772038892035982771"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-10-08T01:07:55.296398Z",
     "start_time": "2023-10-08T01:07:55.289895Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "convert to tensorflow dataset"
   ],
   "metadata": {
    "collapsed": false,
    "id": "0VHMxhx-_yDj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate the model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Gw3JUS7C_yDj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1696714059987,
     "user": {
      "displayName": "Chris Lomeli",
      "userId": "08772038892035982771"
     },
     "user_tz": 420
    },
    "id": "UJ7ov7NvadQV",
    "outputId": "6d3a7cc2-60ec-476a-e5da-e7886782ade7",
    "ExecuteTime": {
     "end_time": "2023-10-08T01:07:55.296630Z",
     "start_time": "2023-10-08T01:07:55.292676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model  sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "model_id=get_config(\"model_id\")\n",
    "print(\"Using model \", model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "id": "_xWFhYnx_yDk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3983,
     "status": "ok",
     "timestamp": 1696714063969,
     "user": {
      "displayName": "Chris Lomeli",
      "userId": "08772038892035982771"
     },
     "user_tz": 420
    },
    "id": "SDCkbfBOahgd",
    "outputId": "76a17f61-6a40-4ba2-d45e-6e2c3c2d4fd0",
    "ExecuteTime": {
     "end_time": "2023-10-08T01:07:57.626792Z",
     "start_time": "2023-10-08T01:07:55.295955Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 18:07:56.882613: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-07 18:07:56.882636: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  22713216  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22713216 (86.64 MB)\n",
      "Trainable params: 22713216 (86.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf_model = TFAutoModel.from_pretrained(model_id)\n",
    "tf_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wrap in our custom model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "P6JiXhXz_yDk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1696714063969,
     "user": {
      "displayName": "Chris Lomeli",
      "userId": "08772038892035982771"
     },
     "user_tz": 420
    },
    "id": "ToztH7XIavz5",
    "ExecuteTime": {
     "end_time": "2023-10-08T01:07:57.634331Z",
     "start_time": "2023-10-08T01:07:57.627611Z"
    }
   },
   "outputs": [],
   "source": [
    "model=TransformerModel(tf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T01:07:57.752038Z",
     "start_time": "2023-10-08T01:07:57.632200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model path /Users/christopherlomeli/Source/courses/datascience/Springboard/capstone/capstone3/data/model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_path=get_config(\"model_path\")\n",
    "print(\"Using model path\", model_path)\n",
    "\n",
    "weights_file = os.path.join(model_path, 'model_weights.h5')\n",
    "tf_model.load_weights(weights_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T01:07:57.860711Z",
     "start_time": "2023-10-08T01:07:57.756591Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"0\"></a>\n",
    "<div style=\"background-color: teal; padding: 10px;\">\n",
    "    <h3 style=\"color: white;\">Return the top 5 products that match the customer query</h3>\n",
    "</div>\n",
    "\n",
    "\n",
    "This was trained on a smaller portion of the whole tokenized dataset, so we do not expect perfection - this is just a test\n",
    "\n",
    "We see that the model was mostly correct for our customer query for a pencil, but we did get s VOW sexy pencil dress as a hot, so we would need the full model and some tweaking to do better\n",
    "\n",
    "I'm running the whole dataset on Colab, and may adjust these findings\n",
    "\n",
    "\n",
    "A next step would be to create a test set for calculating an f1 score, but for this kind of model it's not out-of-the-box, as it is with tabular data.\n",
    "\n",
    "We would need to:\n",
    " \n",
    "- pull a test set of queries, \n",
    "\n",
    "- pick the top products for each query\n",
    "\n",
    "- then we could run 'inference' and we have here for each query, and then score the results\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=teal> Pick the top 5 products for the customer query of \"a blue hb pencil\"</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding files already exist, no need to remake them....\n",
      "(1, 384)\n",
      "(0, array([\"L'VOW Sexy Ruched Pencil Dress for Women Spaghetti Strap Bodycon Backless Maxi Formal Dress(Black,X-Large)\"],\n",
      "      dtype='<U400'))\n",
      "(1, array(['Beginner Primary Size Pencils, Wood-Cased #2 HB Soft Without Eraser, Yellow, 12-Pack - New'],\n",
      "      dtype='<U400'))\n",
      "(2, array(['Wood-Cased #2 HB Pencils, Yellow, Pre-sharpened, Class Pack, 1000 pencils'],\n",
      "      dtype='<U400'))\n",
      "(3, array(['TICONDEROGA My First Pencils, Wood-Cased #2 HB Soft, Pre-Sharpened with Eraser, Yellow, 12-Pack (33312)'],\n",
      "      dtype='<U400'))\n",
      "(4, array(['TICONDEROGA Laddie Pencils, Wood-Cased #2 HB Soft without Eraser, Yellow, 12-Pack (13040)'],\n",
      "      dtype='<U400'))\n"
     ]
    }
   ],
   "source": [
    "from src.inference import InferenceEngine\n",
    "\n",
    "customer_query = \"a blue hb pencil\"\n",
    "\n",
    "# the code for the inference engine is in the inference.py source file\n",
    "inference_engine = InferenceEngine(tf_model=tf_model, tokenizer=tokenizer)\n",
    "\n",
    "# query the engine for the top 5 matches to the customer query\n",
    "results = inference_engine.query(customer_query, top=5)\n",
    "\n",
    "# print out the top 5 matches\n",
    "for r in results:\n",
    "    print(r)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T01:08:08.448174Z",
     "start_time": "2023-10-08T01:07:57.856501Z"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1J4xYWJ1QBFctHuzEAS2BIKbA6fb0M1qX",
     "timestamp": 1696718116479
    }
   ]
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
